"File_Name";"Content";"Category";"Complete_Filename"
"402.txt";"The Mouse Brain As A Gatekeeper For AI And Autonomous Cars

By Lance Eliot, the AI Trends Insider  

Mice can be amazingly smart, mightily so. We all would likely agree that mice are quick on their feet and physically agile. On a personal level, I’ve dealt with mice that decided to take up residence at my home and were determined to stay without my permission and without paying any rent. Upon witnessing a mouse running around in my domicile, I rushed over to the local store and got an everyday mousetrap.   

Turns out that the mice avoided the thing and probably got quite a laugh at my having set it up to begin with. Let’s refer to them as mocking mice, in addition to being mighty mice.   

I watched numerous popular online videos claiming to provide a guaranteed-to-work formula to catch a mouse. Those darned clever mice seemed to escape each one.   

I finally threw in the towel and did what my colleagues and friends had suggested all along. I got a cat.   

I don’t know if my beloved cat dispatched the mice directly, or maybe they headed for the hills after realizing that there was a new sheriff in town. As I said, mice can be very cunning.   

Scientists would say that mice are reasonably intelligent beings. They are being analyzed and scrutinized on a daily basis. The assumption is that mice can reveal all sorts of insights about animals in general, and about mammals in particular, and hopefully provide a helpful glimpse into the nature of human brains and human capabilities.  

They seem to have short-term memory and a long-term memory. Mice will figure out more expedient paths of a maze and seek to optimize their self-behavior. They seem to be able to work in teams, making use of various communications to coordinate their joint activities. It is believed that the communications take place via sound, touch, smell, urination, and even by the act of thumping their appendages.   

Mice might be a crucial pathway toward figuring out the human brain. Mice might also be a crucial pathway toward devising Artificial Intelligence (AI) in machines.   

Say what? 

Yes, the more we can identify how brains work, mice or humans, the better chance we would seem to have toward crafting AI systems. If we can somehow reverse engineer brains, we might be able to create AI systems that do more of what brains do. Some believe that we will simply mimic or simulate the wetware of brains. Others indicate that we might not need to do such mimicry and can instead glean insights to devise AI systems that are able to exhibit intelligent behavior, though they might be made in completely different ways than that of wetware brains.   

You can conceive of efforts in AI as racing forward on multiple fronts at once.   

There are those that don’t especially pay attention to the biomedical efforts of brain reverse engineering. They are fine with such work taking place, but the pace and progress have little bearing on their AI efforts. Absent any hard-and-fast tangible indications from the wetware focus, those AI developers and researchers are forging ahead anyway. No need to wait for the bio side to pin down how the brain operates. 

Meanwhile, there are other AI developers and researchers that closely monitor or are directly involved in these wetware examinations. This is then infused into their AI constructions. The AI use of Machine Learning (ML) and Deep Learning (DL) is notably influenced by and tends to use Artificial Neural Networks (ANNs), which are somewhat akin to wetware neural networks, though decidedly less so and not on par (as yet).   

The thing is, there is a huge debate about whether having tons upon tons of something that runs on a machine in a computer-based way that mimics neurons is ever going to arise to intelligent behavior in the manner that we construe intelligence. If we don’t also come to understand how intelligence arises from the neurons and their interconnections in wetware, we might be doomed to having merely a humongous network of computer-based simulated neurons that aren’t particularly overwhelmingly impressive.   

Perhaps we might get AI toward parts of intelligent behavior via these massive ANN’s and then get stuck. The widespread supposition is that the only way to get unstuck will involve decoding how brains give rise to intelligence in the natural world.   

The mighty mouse might be a significant step in that direction.   

Where might a better devised AI be used, namely an AI that might be shaped around what we ultimately learn from the brains of mice? The mouse brain could be one of the cornerstones or keys to achieving AI-based true self-driving cars.   

The future of cars consists of AI-based true self-driving cars. There isn’t a human driver involved in a true self-driving car. Keep in mind that true self-driving cars are driven via an AI driving system. There isn’t a need for a human driver at the wheel, and nor is there a provision for a human to drive the vehicle.   

Here’s an intriguing question that is worth pondering: How might the insights from reverse-engineering the brains of those lovable and clever mice somehow stoke the advent of AI-based true self-driving cars?   

I’d like to first further clarify what is meant when I refer to true self-driving cars.   

For my framework about AI autonomous cars, see the link here: https://aitrends.com/ai-insider/framework-ai-self-driving-driverless-cars-big-picture/   

Why this is a moonshot effort, see my explanation here: https://aitrends.com/ai-insider/self-driving-car-mother-ai-projects-moonshot/   

For more about the levels as a type of Richter scale, see my discussion here: https://aitrends.com/ai-insider/richter-scale-levels-self-driving-cars/   

For the argument about bifurcating the levels, see my explanation here: https://aitrends.com/ai-insider/reframing-ai-levels-for-self-driving-cars-bifurcation-of-autonomy/ 

Understanding The Levels Of Self-Driving Cars 

As a clarification, true self-driving cars are ones where the AI drives the car entirely on its own and there isn’t any human assistance during the driving task.   

These driverless vehicles are considered Level 4 and Level 5, while a car that requires a human driver to co-share the driving effort is usually considered at Level 2 or Level 3. The cars that co-share the driving task are described as being semi-autonomous, and typically contain a variety of automated add-on’s that are referred to as ADAS (Advanced Driver-Assistance Systems).   

There is not yet a true self-driving car at Level 5, which we don’t yet even know if this will be possible to achieve, and nor how long it will take to get there.   

Meanwhile, the Level 4 efforts are gradually trying to get some traction by undergoing very narrow and selective public roadway trials, though there is controversy over whether this testing should be allowed per se (we are all life-or-death guinea pigs in an experiment taking place on our highways and byways, some contend). 

Since semi-autonomous cars require a human driver, the adoption of those types of cars won’t be markedly different from driving conventional vehicles, so there’s not much new per se to cover about them on this topic (though, as you’ll see in a moment, the points next made are generally applicable).  

For semi-autonomous cars, it is important that the public needs to be forewarned about a disturbing aspect that’s been arising lately, namely that despite those human drivers that keep posting videos of themselves falling asleep at the wheel of a Level 2 or Level 3 car, we all need to avoid being misled into believing that the driver can take away their attention from the driving task while driving a semi-autonomous car.   

You are the responsible party for the driving actions of the vehicle, regardless of how much automation might be tossed into a Level 2 or Level 3. 

For why remote piloting or operating of self-driving cars is generally eschewed, see my explanation here: https://aitrends.com/ai-insider/remote-piloting-is-a-self-driving-car-crutch/  

To be wary of fake news about self-driving cars, see my tips here: https://aitrends.com/ai-insider/ai-fake-news-about-self-driving-cars/  

The ethical implications of AI driving systems are significant, see my indication here: https://aitrends.com/selfdrivingcars/ethically-ambiguous-self-driving-cars/   

Be aware of the pitfalls of normalization of deviance when it comes to self-driving cars, here’s my call to arms: https://aitrends.com/ai-insider/normalization-of-deviance-endangers-ai-self-driving-cars/   

Self-Driving Cars And The Mouse That Roared   

For Level 4 and Level 5 true self-driving vehicles, there won’t be a human driver involved in the driving task. All occupants will be passengers; the AI is doing the driving. 

One aspect to immediately discuss entails the fact that the AI involved in today’s AI driving systems is not sentient. In other words, the AI is altogether a collective of computer-based programming and algorithms, and most assuredly not able to reason in the same manner that humans can.   

Why is this added emphasis about the AI not being sentient? 

Because I want to underscore that when discussing the role of the AI driving system, I am not ascribing human qualities to the AI. Please be aware that there is an ongoing and dangerous tendency these days to anthropomorphize AI. In essence, people are assigning human-like sentience to today’s AI, despite the undeniable and inarguable fact that no such AI exists as yet.   

With that clarification, you can envision that the AI driving system won’t natively somehow “know” about the facets of driving. Driving and all that it entails will need to be programmed as part of the hardware and software of the self-driving car. 

Let’s dive into the myriad of aspects that come to play on this topic.   

We are considering how mouse brains might be useful for making further progress on achieving AI-based true self-driving cars.   

It would seem apparent that we know everything there is to know about how humans drive. 

The thing is, all of those discernible rules and abundant logic about the driving act are ultimately converted into the human brain. Once the whole kit and caboodle go into your brain, we really do not know what takes place. The brain in terms of turning all that wetware machinations into human thinking is still an abundant mystery. 

In short, if studies of the brains of mice could reveal the innermost secrets of how the brain arises to the task of thinking, we might be able to unlock the same as it pertains to human thought. And, if we did that, we would have a much clearer understanding of what goes through the human mind during the driving chore. Some ardently believe that the vaunted and revered Level 5 will not be achieved unless we can first unpack the inner workings of human thought.   

That being said, I would not want to imply that the glories of finally figuring out how humans think are going to be used simply to garner autonomous vehicles and self-driving cars. You can bet your bottom dollar that a lot more could be achieved with AI that leveraged or exploited the byzantine complexities of the human brain. 

For more details about ODDs, see my indication at this link here: https://www.aitrends.com/ai-insider/amalgamating-of-operational-design-domains-odds-for-ai-self-driving-cars/ 

On the topic of off-road self-driving cars, here’s my details elicitation: https://www.aitrends.com/ai-insider/off-roading-as-a-challenging-use-case-for-ai-autonomous-cars/ 

I’ve urged that there must be a Chief Safety Officer at self-driving car makers, here’s the scoop: https://www.aitrends.com/ai-insider/chief-safety-officers-needed-in-ai-the-case-of-ai-self-driving-cars/ 

Expect that lawsuits are going to gradually become a significant part of the self-driving car industry, see my explanatory details here: https://aitrends.com/selfdrivingcars/self-driving-car-lawsuits-bonanza-ahead/   

Conclusion 

Start small and make our way to something big, really big.   

We can welcome and seek to squeeze every ounce of insight from the mapping of the mouse brain. A lot more mapping is going to be needed. Be thankful for those gallant mice that contribute to this grand quest.   

A final comment for now. 

The approximate estimated count for the number of human neurons in our brains is around 86 billion. For a mouse it is something akin to 70 million. Recall how I obtained a cat, partially prompted to deal with my mouse problem at home.   

The estimate of the number of neurons in the brain of a cat is around 250 million. On a rough comparison, this means that the cat has perhaps three to four times the number of neurons of a mouse. Please note that you have to be careful making any generalizations by the sheer count of neurons alone, since that’s not the only factor involved.   

But, I’m sure your neighborhood cat thinks it can outsmart those troublesome mice, and the feline is eagerly and earnestly willing to prove to you that by far a cat is heads and shoulders smarter than those annoying mouse freeloaders underfoot. 

The race to figure out how to best attain AI is akin to a cat and mouse gambit that we don’t yet know how it will play out. It is going to be exciting, that’s for darn sure.  

Copyright 2021 Dr. Lance Eliot  ";"tech";"402.txt-tech"


"403.txt";"14 Tech Experts Predict Exciting Future Features Of Driverless Cars
While truly “driverless” cars may not be widely available for some time to come, there is potential for the autonomous vehicles of the future to do a lot more than just take passengers from point A to point B.

Driverless cars may be in their infancy, but they’re certainly generating a lot of interest. Most major car companies, as well as several startups, have autonomous vehicle projects in the works. While most current designs blend sensor- and AI-enabled navigation with the ability for the human operator to take over, most companies building autonomous vehicles envision a future in which the automobile itself handles all the driving. 

While truly “driverless” cars may not be widely available for some time to come, there is potential for the autonomous vehicles of the future to do a lot more than just take passengers from point A to point B. Below, 14 industry experts from Forbes Technology Council share their predictions for features future driverless will offer their passengers.

1. Fully Functioning Office Spaces

We make the best use of long commutes by making work calls or listening to podcasts; however, that’s soon to change. In the near future, driverless cars will act as fully functioning mobile offices. Equipped with Wi-Fi and served by 5G networks, these futuristic cars will be a staple for the modern business person, adding an entirely new avenue of productivity into the workforce. - Marc Fischer, Dogtown Media LLC

2. Additional Entertainment Options

The driverless car arena has been filled with hype for many years, but the bridge to full autonomy is long. With that in mind, I think self-driving cars will become mobile offices, shuttles or delivery units and be relegated to niche, low-speed routes in large cities or basic planned routes. These vehicles can provide more entertainment options and increased safety features and will be highly customizable. - Ernie Bray, AutoClaims Direct Inc. (ACD)

Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?

3. Ability To Learn Routines And Preferences

Driverless cars can leverage their machine learning capabilities to learn the routines and preferences of their passengers, thereby providing greater assistance by automatically performing routine tasks such as ensuring on-time arrival for work or appointments, finding a cheap parking spot in dense cities or preferentially driving to stores where specific, desired products are in stock. - Sreekanth Mallikarjun, Reorg

4. Enhanced Safety Features

Ironically, the feature that will get the most attention is safety. We need regulations that define ethics for the algorithms and tech that does a better job detecting other objects and levels of traffic, so the fastest route is exactly that. We’re close, and 5G will help. Even further in the future, autonomous cars that fly would be awesome. Does that sound like sci-fi? I can only say that the Jetsons are not as “out of this world” as they used to be. - Robert Strzelecki, TenderHut

5. Safe Driving Modes

Young kids are very eager to get their learner’s permits, which is a big source of anxiety for parents. I feel a safe driving mode will help relieve parents—the mode will always be on, and the kick that young drivers get out of speeding will be kept under control. - Bhavna Juneja, Infinity, a Stamford Technology Company

6. Additional Cargo Capacity

Simple cargo capacity will be game-changing. Being able to load a driverless car or truck with cargo and set the destination to deliver goods to a recipient across the city will provide a much-needed revolution for the mail and package delivery industries. Adding larger batteries in place of passenger space would increase range and allow for interstate deliveries. - Greg Young, Uniform Law Commission

7. Better Privacy And Cybersecurity Features

Future driverless cars will incorporate more privacy and security features. Firewalls in cars will be normalized. Protection of the driver’s data will become paramount, and it will likely be regulated. You can tell a lot about someone based on where, when and how they drive. Advertisers would love to get their hands on that data, and hackers would love to exploit it. We have to protect it. - Jerich Beason, Epiq

8. Enhanced Accessibility

Driverless cars will enrich our lives in many ways. They’ll provide new levels of accessibility, allowing people who currently aren’t able to drive to move freely and safely. While AVs are in their infancy, we’re also eager to see developments that optimize and personalize rider experiences, allowing commuters to stream entertainment, video chat with co-workers or scan social feeds. - Brett Wheatley, TransLoc

9. In-Vehicle Advertising

Advertising will be a big part of the experience at some point. While on the way to your destination, you’ll be able to add a stop for shopping or food, and companies will be vying for that recommendation. At a glance, you’ll be able to see the extra time needed and be able to order in transit. You’ll be able to avoid the ads by paying more, but many will want to subsidize their travel costs. - Luke Wallace, Bottle Rocket

10. Shared Ownership Options

Shared ownership will be a bonus of future self-driving cars. The real value of self-driving cars is that they can be used by someone else when you don’t need them. Current cars have no value except when they’re in use. Self-driving cars can be used as part of ride-sharing services or within partial ownership agreements with nearby families. This will reduce the number of cars we need, making driving more sustainable without loss of convenience. - Kevin Parikh, Avasant

11. Customizable Interiors

Future driverless cars will feature configurable interiors that will allow them to be transitioned from multi-person vehicles to offices, entertainment spaces and service locations. Also, they will be extremely useful for people who are elderly, disabled or in wheelchairs who need assistance getting in and out of the vehicle. - Laureen Knudsen, Broadcom

12. Augmented Reality Navigation

Future vehicles will have the entire windshield to use for augmented reality systems, thus giving passengers the ability to summon augmented reality navigation systems on the screens. This will allow data such as directions and location to be projected onto the windshield, transforming the driving experience. - Roman Taranov, Ruby Labs

13. Robust Communications Systems

Future driverless cars will be able to communicate with each other as well as with retailers and restaurants, enabling curbside and drive-through pickups. Authorized e-commerce companies will be able to access and deliver items directly to the vehicle’s trunk. Additionally, driverless cars will offer a variety of interiors, including living room, office workspace and entertainment room options, and cameras will be connected to the home security system. - Selva Pandian, DemandBlue

14. Hybrid Road And Air Capabilities

The driverless cars of the future will feature drone-like capabilities of flight, leveraging both road and air travel. Once the airspace regulations and infrastructure are updated to enable this type of hybrid model, autonomous vehicle fleets at scale could be realized, because they would not be interacting with human-driven machines while in transit. - Thomas Helfrich, System Soft Technologies";"tech";"403.txt-tech"


"404.txt";"Audi's Grandsphere concept envisions autonomous vehicle as living room
The spacious Grandsphere interior replaces the traditional huge blackened touch screen prevalent in most such luxury vehicles.

According to Audi, the future of autonomous driving is ... reclined much of the time.

The German premium brand on Thursday introduced the Grandsphere, the second of three planned concept vehicles it says lay out a future for its products as it transitions to an all-electric lineup that will include models with Level 4 autonomous-driving capability. Brand executives said they intend to sell a Level 4-capable vehicle to consumers by 2026. The first concept, named Skysphere, was shown last month; the Urbansphere will be shown next year.

The Grandsphere, a large luxury sedan with two front-row seats and a rear bench, has two main highlights: the brand's coming cat-eye LED exterior lighting signature and a bespoke interior that reimagines how the vehicle's passengers will spend their time while the vehicle is driving itself.

Accessed via large portal doors, the spacious Grandsphere interior replaces the traditional huge blackened touch screen prevalent in most such luxury vehicles with one projected across a wooden substructure that wraps across the vehicle from door to door. The wheel and control functions are hidden behind a hinged panel in the dashboard and emerge only on command from the driver. Most of the concept's functions are controlled by gesture, voice command or a distinct look from the driver that is picked up by the vehicle's sensors.
With drivers freed from the task of actually controlling the vehicle, Audi's designers equipped the Grandsphere with front seats that recline up to 60 degrees, allowing front-row passengers to fully relax while the vehicle drives itself, and entertaining them with music or videos on the broad screen. Audi says the interior transforms the automobile into an experience device.

While the Grandsphere is a concept, Oliver Hoffmann, a member of the Audi board of management for development, says the concept shows how the industry must rethink its entire design process for EVs and autonomous driving.

Highly autonomous driving is a game changer, because it means we are developing and designing cars from the inside out, Hoffmann explained.

With autonomous driving, one key element changes dramatically: The driver need not have the wheel in his hands all the time. That turns the car into a lounge, he said through an interpreter. We give the customer time to relax, to work, to entertain themselves. The car becomes the biggest mobile device you can imagine. And that offers huge new possibilities.";"tech";"404.txt-tech"

"405.txt";"Tech could help autonomous vehicles read signs
A UB-led study explains the physics behind reflective microscale concave interfaces — structures that reflect light in fascinating ways.

Research News
A scanning electron microscope image shows the microscale concave interface structure consisting of microspheres partially embedded in sticky tape, forming microscale concave interfaces. 
A scanning electron microscope image shows the microscale concave interface structure that was studied. The material consists of microspheres partially embedded in sticky tape, forming microscale concave interfaces. Image: Jacob Rada

By CHARLOTTE HSU
Published September 3, 2021

headshot of Qiaoqiang Gan. 
A new study explains the science behind microscale concave interfaces (MCI) — structures that reflect light to produce beautiful and potentially useful optical phenomena.

“It is vital to be able to explain how a technology works to someone before you attempt to adopt it. Our new paper defines how light interacts with microscale concave interfaces,” says UB engineering researcher Qiaoqiang Gan, noting that future applications of these effects could include aiding autonomous vehicles in recognizing traffic signs.

The research was published online Aug. 15 in Applied Materials Today, and is featured in the journal’s September issue.

Gan, professor of electrical engineering, School of Engineering and Applied Sciences, led the collaborative study, which was conducted by a team from UB, the University of Shanghai for Science and Technology, Fudan University, Texas Tech University and Hubei University. The first authors are Jacob Rada, UB PhD student in electrical engineering, and Haifeng Hu, professor of optical-electrical and computer engineering at the University of Shanghai for Science and Technology.

Reflections that form concentric rings of light
The study focuses on a retroreflective material — a thin film that consists of polymer microspheres laid down on the sticky side of a transparent tape. The microspheres are partially embedded in tape, and the parts that protrude form MCIs.​

White light shining on this film is reflected in a way that causes the light to create concentric rainbow rings, the new paper reports. Alternately, hitting the material with a single-colored laser (red, green or blue, in the case of this study) generates a pattern of bright and dark rings. Reflections from infrared lasers also produced distinctive signals consisting of concentric rings.

Concentric rainbows. 
Concentric rainbows are produced when white light is reflected by microscale concave interfaces. This image shows the experimental set-up. Image: Jacob Rada

The research describes these effects in detail, and reports on experiments that used the thin film in a stop sign. The patterns formed by the material showed up clearly on both a visual camera that detects visible light, and a LIDAR (laser imaging, detection and ranging) camera that detects infrared signals, says Rada, the co-first author from UB.

“Currently, autopilot systems face many challenges in recognizing traffic signs, especially in real-world conditions,” Gan says. “Smart traffic signs made from our material could provide more signals for future systems that use LIDAR and visible pattern recognition together to identify important traffic signs. This may be helpful to improve the traffic safety for autonomous cars.”

Visible (left) and infrared (right) images of a sign created using microscale concave interfaces to form the word STOP and other elements. 
Visible (left) and infrared (right) images of a sign created using microscale concave interfaces to form the word STOP and other elements. The infrared image was taken using a LIDAR (laser imaging, detection and ranging) camera. Image: Jacob Rada

“We demonstrated a new combined strategy to enhance the LIDAR signal and visible pattern recognition that are currently performed by both visible and infrared cameras,” Rada explains. “Our work showed that the MCI is an ideal target for LIDAR cameras, due to the constantly strong signals that are produced.”

A U.S. patent for the retroreflective material has been issued, as well as a counterpart in China, with Fudan University and UB as the patent-holders. The technology is available for licensing.

Gan says future plans include testing the film using different wavelengths of light and different materials for the microspheres, with the goal of enhancing performance for possible applications such as traffic signs designed for future autonomous systems.

In addition to Gan, Rada and Hu, authors of the new Applied Materials Today study include PhD candidate Lyu Zhou, Research Assistant Professor Haomin Song and PhD graduate Xie Zeng, all from the UB Department of Electrical Engineering; Jing Zeng and Limin Wu from Fudan University; Shakil Shimul and Wei Li from Texas Tech University; Wen Fan from Hubei University; and Qiwen Zhan from the University of Shanghai for Science and Technology. The research was partially funded by a grant from the U.S. National Science Foundation.";"tech";"405.txt-tech"

"005.txt";"Do passengers want self-driving cars to behave more or less human?
Recent studies have shown that people have negative attitudes about using autonomous systems because they don't trust them. Moreover, research shows a human-centered approach in autonomy is perceived as more trustworthy by users. This begs the question: Do passengers want self-driving cars to mimic their personal driving behaviors or do they hold these autonomous vehicles to a different standard?

To explore this quandary, researchers from Florida Atlantic University's College of Engineering and Computer Science conducted a study asking 352 participants about their personal driving behaviors such as speed, changing lanes, distance from a car in front of them, accelerating and decelerating and passing other vehicles. They also asked them the same questions about their expectations of a self-driving car performing these very same tasks. The objective of the study was to examine trust and distrust to see if there is a relationship between an individual's driving behaviors and how they expect a self-driving car to behave.

For the study, published in the proceedings HCI in Mobility, Transport and Automotive Systems, researchers asked the participants 46 questions to gain a better understanding of driving behavior and driver's expectations of self-driving cars in a variety of driving scenarios. Ultimately, information from this study can be used to construct driving models for self-driving cars.

Interestingly, results showed that most people prefer a self-driving car that drives like a less aggressive version of their own driving behaviors. Participants who reported that they trust or somewhat trust artificial intelligence, autonomous technologies, and self-driving cars expected a car with behaviors similar to their personal driving behaviors. Researchers also found that the expectation of a self-driving car's level of attenuated aggressiveness witnessed among all other participants was relative to their personal driving behavior aggressiveness. For example, male drivers showed to be more aggressive drivers than female drivers, and therefore, their expectations for a self-driving car was slightly more aggressive.

We found that current attitudes toward artificial intelligence, autonomous technologies, and self-driving cars had an effect on our participants' expectations of a self-driving car, said Mehrdad Nojoumian, Ph.D., senior author, and an associate professor in the Department of Electrical Engineering and Computer Science and director of the Privacy, Security and Trust in Autonomy Lab, who co-authored the paper with Jamie Craig, a graduate student and a graduate research assistant in the Department of Electrical Engineering and Computer Science. The one group that stood out to us were those who trust or somewhat trust using AI, autonomous technologies, and self-driving cars. Their driving behavior aggressiveness scores and their self-driving aggressiveness scores were not significantly different, and they would want a car that matched their personal driving behavior.

The article recently received Best Paper Award from the Third International Conference on HCI in Mobility, Transport and Automotive Systems, awarded to Nojoumian and Craig, who presented the findings of the paper at the conference.

The closer the automated vehicle dynamics are with those of a manually driven vehicle, the more likely that the comfort level of the automated vehicle user will improve, said Stella Batalama, Ph.D., dean, College of Engineering and Computer Science. Results from this study can be considered by engineers, computer scientists and researchers and will be useful in developing certain profiles or settings for self-driving cars and overall can help in designing one that is perceived as trustworthy by passengers.";"tech";"005.txt-tech"

